{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gut-puncture/Compound_Embedding_Reasoning/blob/main/Compound_Embedding_Reasoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8s_rV8ElvbE"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t63tE2sUE0Rs",
        "outputId": "d2c99074-33cb-4adb-c83c-58478a315b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # connecting google drive to this notebook\n",
        "\n",
        "!pip -q install --upgrade \"transformers==4.41.2\" \"accelerate>=0.29.0\" \\\n",
        "                \"sentencepiece\" \"datasets>=2.19.0\" \"pandas\" \"matplotlib\" \"huggingface_hub>=0.23.0\" \"fsspec>=2024.3.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHgAhE_lyoR"
      },
      "source": [
        "##Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hXbNZitQgbd"
      },
      "outputs": [],
      "source": [
        "import torch, re, math, pandas as pd, matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import random, textwrap\n",
        "\n",
        "# ---------- paths ---------------------------------------------------------\n",
        "MODEL_DIR           = \"/content/drive/MyDrive/phi3_3.8B\"   # NEED THIS MODEL TO BE PRESENT IN GOOGLE DRIVE\n",
        "BASELINE_HF_MODEL   = \"microsoft/phi-3-mini-4k-instruct\"   # reference\n",
        "\n",
        "# ---------- thinking parameters ------------------------------------------\n",
        "ALPHA               = 0.25\n",
        "COMPOUND_P          = 0.8\n",
        "SAMPLE_P            = 0.80\n",
        "STOP_ENTROPY        = 0.1   # entropy threshold (nats) below which we count steps\n",
        "LENGTH_THRESHOLD    = 8      # consecutive low-entropy steps for Cold-Stop\n",
        "MAX_THINK_STEPS     = 200\n",
        "\n",
        "# ---------- token markers -------------------------------------------------\n",
        "REASON_START = \"### Reasoning:\\n\"\n",
        "REASON_END   = \"###\"\n",
        "ANS_START    = \"### Answer:\\n\"\n",
        "\n",
        "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE   = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "\n",
        "# Note: tokenizer will be loaded later in cell 9\n",
        "# We'll add the END_SEQ_CANDIDATES after tokenizer is available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRA7I8k_6WUB"
      },
      "source": [
        "#Helper Functions - Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw6tF_hh6VAB"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def create_compound_vector(model_outputs, embeddings, dtype, p=COMPOUND_P):\n",
        "    logits = model_outputs.logits[:, -1, :]\n",
        "    probs  = torch.softmax(logits, dim=-1)\n",
        "    sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
        "    cum    = torch.cumsum(sorted_probs, dim=-1)\n",
        "    mask   = cum <= p #all elements with cumulative prob less than p are True and all others False in mask\n",
        "    mask[..., 0] = True #first element is hard coded to True so we ALWAYS choose at least one element\n",
        "    sel_idx, sel_prob = sorted_idx[mask], sorted_probs[mask] #selecting all the token ids and their probs for which cumulative prob is less than p\n",
        "\n",
        "    # FIXED: Normalize the probabilities so they sum to 1\n",
        "    weights = sel_prob / sel_prob.sum()\n",
        "    vec = (embeddings(sel_idx) * weights.unsqueeze(-1)).sum(0, keepdim=True)\n",
        "    return vec.to(dtype).unsqueeze(0)\n",
        "\n",
        "def sample_token_normally(model_outputs, p=SAMPLE_P): #essentially the same function as above but gives just the sampled token id\n",
        "    logits = model_outputs.logits[:, -1, :]\n",
        "    probs  = torch.softmax(logits, dim=-1)\n",
        "    sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
        "    mask   = torch.cumsum(sorted_probs, dim=-1) <= p\n",
        "    mask[..., 0] = True\n",
        "\n",
        "    # FIXED: Normalize probabilities before sampling\n",
        "    selected_probs = sorted_probs[mask]\n",
        "    normalized_probs = selected_probs / selected_probs.sum()\n",
        "    choice = torch.multinomial(normalized_probs, 1)\n",
        "    return sorted_idx[mask][choice]\n",
        "\n",
        "def create_thinking_vector(comp_vec, samp_tok, embeddings, dtype, alpha=ALPHA):\n",
        "    samp_emb = embeddings(samp_tok).unsqueeze(0).to(dtype)\n",
        "    return (1-alpha)*samp_emb + alpha*comp_vec.to(dtype) #creating a weigthed sum of the sampled token vector and the compound vector\n",
        "\n",
        "class ThinkGenerator: #Completely AI written\n",
        "    \"\"\"\n",
        "    Callable: prompt -> (answer_text, steps, entropy_list, stopping_reason)\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "        self.model     = AutoModelForCausalLM.from_pretrained(\n",
        "                            model_path, torch_dtype=DTYPE, device_map=\"auto\")\n",
        "        self.embed     = self.model.model.embed_tokens\n",
        "        self.dtype     = next(self.model.parameters()).dtype\n",
        "        self.device    = next(self.model.parameters()).device\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def __call__(self, full_prompt:str):\n",
        "        ids   = self.tokenizer(full_prompt, return_tensors=\"pt\").input_ids.to(self.device) #converts string to tokens\n",
        "        embeds = self.embed(ids).to(self.dtype) #embeddings of the token ids\n",
        "        ent_hist = []\n",
        "        # low_entropy_steps = 0  # Counter for consecutive low-entropy steps   # ‚Üê DISABLED\n",
        "\n",
        "        # Initialize rolling buffer for end token detection\n",
        "        end_buf = deque(maxlen=MAX_END_SEQ_LEN)\n",
        "        reason_end_already_added = False  # FIXED: Track if we already added the end token\n",
        "        stopping_reason = \"max_steps\"  # Default stopping reason\n",
        "\n",
        "        # Reasoning loop for model\n",
        "        # STOPPING CONDITIONS:\n",
        "        # 1. Reasoning end token \"###\" is sampled\n",
        "        # 2. Maximum reasoning steps (MAX_THINK_STEPS) reached\n",
        "        for step in range(MAX_THINK_STEPS):\n",
        "            # FIXED: Add proper attention mask for inputs_embeds\n",
        "            attention_mask = torch.ones(embeds.size()[:2], device=embeds.device)\n",
        "            outs   = self.model(inputs_embeds=embeds, attention_mask=attention_mask) #vector embeddings injected in model rather than token ids\n",
        "            logits = outs.logits[:, -1, :]\n",
        "            p      = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # Calculate entropy (still logged for analysis)\n",
        "            ent_value = -(p * p.log()).sum().item()\n",
        "            ent_hist.append(ent_value)\n",
        "\n",
        "            # --- Cold-Stop disabled -------------------------------------------------\n",
        "            # if ent_value < STOP_ENTROPY:\n",
        "            #     low_entropy_steps += 1\n",
        "            # else:\n",
        "            #     low_entropy_steps = 0\n",
        "            #\n",
        "            # if low_entropy_steps >= LENGTH_THRESHOLD:\n",
        "            #     # Force end-token when Cold-Stop triggers\n",
        "            #     reason_end_tok = torch.tensor([[reason_end_token_id]], device=self.device)\n",
        "            #     plain_emb = self.embed(reason_end_tok).to(self.dtype)\n",
        "            #     embeds = torch.cat([embeds, plain_emb], 1)\n",
        "            #     ids = torch.cat([ids, reason_end_tok], 1)\n",
        "            #     reason_end_already_added = True\n",
        "            #     stopping_reason = \"cold_stop\"\n",
        "            #     break\n",
        "            # -----------------------------------------------------------------------\n",
        "\n",
        "            comp = create_compound_vector(outs, self.embed, self.dtype)\n",
        "            tok  = sample_token_normally(outs)\n",
        "\n",
        "            # Add token to buffer for end sequence detection\n",
        "            end_buf.append(tok.item())\n",
        "\n",
        "            # Check if we've matched any end sequence\n",
        "            break_outer = False\n",
        "            for seq in END_SEQ_CANDIDATES:\n",
        "                if len(end_buf) >= len(seq) and list(end_buf)[-len(seq):] == seq:\n",
        "                    stopping_reason = \"sampled_end_token\"\n",
        "                    reason_end_already_added = True\n",
        "                    break_outer = True\n",
        "                    break\n",
        "\n",
        "            vec  = create_thinking_vector(comp, tok, self.embed, self.dtype)\n",
        "            embeds = torch.cat([embeds, vec], 1) #adding the compound vector to the previous token vectors\n",
        "            ids    = torch.cat([ids, tok.unsqueeze(0)], 1)\n",
        "\n",
        "            if break_outer:\n",
        "                break\n",
        "\n",
        "        # Ensure reasoning end token is always added if we exit due to max steps\n",
        "        if not reason_end_already_added:\n",
        "            # Use the first candidate sequence (should be the simplest \"###\")\n",
        "            reason_end_tokens = torch.tensor([END_SEQ_CANDIDATES[0]], device=self.device)\n",
        "            reason_end_embeds = self.embed(reason_end_tokens).to(self.dtype)\n",
        "            embeds = torch.cat([embeds, reason_end_embeds], 1)\n",
        "            ids = torch.cat([ids, reason_end_tokens], 1)\n",
        "            reason_end_already_added = True\n",
        "            stopping_reason = \"max_steps\"\n",
        "\n",
        "        # Conditional delimiter to avoid duplicate \"###\"\n",
        "        if reason_end_already_added:\n",
        "            # Only add the answer start part since \"###\" is already there\n",
        "            delim_text = f\"\\n{ANS_START}\"\n",
        "        else:\n",
        "            # Add both end and answer start\n",
        "            delim_text = f\"{REASON_END}\\n{ANS_START}\"\n",
        "\n",
        "        delim = self.tokenizer(delim_text, add_special_tokens=False, return_tensors=\"pt\").input_ids.to(self.device)\n",
        "        delim_embeds = self.embed(delim).to(self.dtype)\n",
        "\n",
        "        # Concatenate delimiter embeddings and IDs to maintain compound context\n",
        "        embeds = torch.cat([embeds, delim_embeds], 1)\n",
        "        ids = torch.cat([ids, delim], 1)\n",
        "\n",
        "        # Use both input_ids and inputs_embeds to preserve full context while using compound embeddings\n",
        "        attention_mask = torch.ones_like(ids)\n",
        "        gen = self.model.generate(\n",
        "            input_ids=ids,\n",
        "            inputs_embeds=embeds,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=50,\n",
        "            do_sample=False,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "        text = self.tokenizer.decode(gen[0])\n",
        "        return text, len(ent_hist), ent_hist, stopping_reason\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjVCOqUf1OE"
      },
      "source": [
        "#Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY9geUWH6d44"
      },
      "outputs": [],
      "source": [
        "# Add 8 few-shot examples so we can compare performace with 8 shot eval\n",
        "FEW_SHOT_BLOCK = \"\"\"\n",
        "Example Questions and Answers:\n",
        "Question: If you roll 2 standard six-sided dice, what is the probability that the sum is 5?\n",
        "### Reasoning:\n",
        "The pairs that sum to 5 are (1,4), (2,3), (3,2), (4,1).\\\n",
        "There are 4 favourable outcomes out of 36 total. Probability = 4/36 = 1/9.\n",
        "###\n",
        "### Answer:\n",
        "1/9\n",
        "\n",
        "Question: A rectangle has length 8 cm and width 5 cm. What is its area in square centimetres?\n",
        "### Reasoning:\n",
        "Area = length √ó width = 8 √ó 5 = 40 cm¬≤.\n",
        "###\n",
        "### Answer:\n",
        "40\n",
        "\n",
        "Question: Sarah has 3 red, 4 blue, and 5 green marbles. If she randomly chooses one, what is the probability it is blue?\n",
        "### Reasoning:\n",
        "Total marbles = 3+4+5 = 12. Blue count = 4. Probability = 4/12 = 1/3.\n",
        "###\n",
        "### Answer:\n",
        "1/3\n",
        "\n",
        "Question: What is 15 % of 80?\n",
        "### Reasoning:\n",
        "0.15 √ó 80 = 12.\n",
        "###\n",
        "### Answer:\n",
        "12\n",
        "\n",
        "Question: A train travels 180 km in 3 hours. What is its average speed in km per hour?\n",
        "### Reasoning:\n",
        "Speed = distance / time = 180 / 3 = 60 km/h.\n",
        "###\n",
        "### Answer:\n",
        "60\n",
        "\n",
        "Question: The number x satisfies 3x + 7 = 22. What is x?\n",
        "### Reasoning:\n",
        "3x = 22 ‚àí 7 = 15 ‚áí x = 15/3 = 5.\n",
        "###\n",
        "### Answer:\n",
        "5\n",
        "\n",
        "Question: A square has perimeter 24 cm. What is the length of one side in centimetres?\n",
        "### Reasoning:\n",
        "Perimeter = 4s ‚áí s = 24/4 = 6 cm.\n",
        "###\n",
        "### Answer:\n",
        "6\n",
        "\n",
        "Question: Mike scores 70, 80, 90 on three tests. What average must he score on a 4th test to have a mean of 85?\n",
        "### Reasoning:\n",
        "Desired total = 85√ó4 = 340. Current total = 70+80+90 = 240. Needed = 340‚àí240 = 100.\n",
        "###\n",
        "### Answer:\n",
        "100\n",
        "\"\"\".strip()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI model which is being evaluated to see how well you're able to solve few reasoning questions which all have integer answers.\n",
        "From the next line, I have given you a few examples of the kind of questions you can expect, how you must reason to solve them and how to answer.\n",
        "Then you will see the words \"Test Question\" which will be the question you need to answer in the test.\n",
        "Think between the reasoning tokens and then write the answer. You must always end the reasoning with the token \"###\" but only and only when you're ready to provide the answer.\n",
        "Once you're done with reasoning, you can provide the answer.\n",
        "The first integer after \"### Answer:\\n\" in your generation will be what I will take as your answer and if it doesn't match with the answer given, I will give you 0 reward.\n",
        "Even more important is to simply answer just the test question and stop generating tokens after the integer answer. \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QtRKv8O-JGL",
        "outputId": "7436d163-e408-4d9e-d884-2bdc4da475ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import random, textwrap\n",
        "\n",
        "gsm_test  = load_dataset(\"gsm8k\", \"main\", split=\"test\").shuffle(seed=21).select(range(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ef76fa45ffc14e4faa3b0f859c411c70",
            "7e8eef8ec479465991d23d52a8d8e096",
            "9e57e969811e4657a0345f9e88011d6b",
            "c037d4869a2d4d61bfe10c1e1287290f",
            "c6256089aaad471290c1822f963a1d19",
            "a74410ef8b5646f9a78d2fec5aebd67a",
            "74249229106d4000b892248499778635",
            "ff6f559346704e81bacb163aedbae15e",
            "177d2a74408b439e87189275be492b89",
            "3728fa2f53b54cefb89ec90cf17e9e42",
            "0281bcbd48db41389320ad61e3a35638",
            "5257c3774ff74ef2b1cfe8b2b5ca7db9",
            "93a2f68635b94c30817b5952911c1d5a",
            "85a07f5a623d4f778f70d55e13b1f169",
            "065d9ab425b74f1f81172b04d9a00222",
            "502cb2ebfa0e4346b9600b77c5ac15d3",
            "79618bcaf1e44155bafd7e1026a94ad6",
            "2f9bdcda46744624b9ee959622480bef",
            "f8ac3badae8a4795a617f56d4b99ce58",
            "d695db113fc146b6b35ce99ccc05624a",
            "8dfa9e9f3f3342a7a8483405191edb9c",
            "4b20733318374082b4c2f719ab8887f5"
          ]
        },
        "collapsed": true,
        "id": "VAECdrmN3Yk0",
        "outputId": "4db1b3af-c1f1-4176-dc08-0fb04b1bd41e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef76fa45ffc14e4faa3b0f859c411c70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5257c3774ff74ef2b1cfe8b2b5ca7db9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tok_base  = AutoTokenizer.from_pretrained(BASELINE_HF_MODEL, trust_remote_code=True)\n",
        "mod_base  = AutoModelForCausalLM.from_pretrained(BASELINE_HF_MODEL,\n",
        "                                                 torch_dtype=DTYPE, device_map=\"auto\")\n",
        "\n",
        "# --- reasoning-end detection ------------------------------------------\n",
        "REASON_END_RAW = \"###\"\n",
        "END_SEQ_CANDIDATES = [\n",
        "    tok_base.encode(\"###\", add_special_tokens=False),\n",
        "    tok_base.encode(\" ###\", add_special_tokens=False),\n",
        "    tok_base.encode(\"\\n###\", add_special_tokens=False),\n",
        "    tok_base.encode(\"\\n ###\", add_special_tokens=False),\n",
        "]\n",
        "MAX_END_SEQ_LEN = max(len(seq) for seq in END_SEQ_CANDIDATES)\n",
        "\n",
        "think_gen = ThinkGenerator(MODEL_DIR)\n",
        "\n",
        "def build_prompt(question: str) -> str:\n",
        "    return f\"{SYSTEM_PROMPT}\\n{FEW_SHOT_BLOCK}\\n\\n Test Question: {question}\\n{REASON_START}\"\n",
        "\n",
        "def gold_int(ans: str) -> str:\n",
        "    ints = re.findall(r\"-?\\d+\", ans)\n",
        "    return ints[-1] if ints else \"\" #results in the final integer in the model's generation\n",
        "\n",
        "@torch.inference_mode()\n",
        "def baseline_answer(question: str) -> str:\n",
        "    prompt = build_prompt(question)\n",
        "    ids    = tok_base(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "    gen    = mod_base.generate( #answer generate by vanilla model for comparison. we defined the vanilla model's name and simply use that.\n",
        "                ids,\n",
        "                max_new_tokens=256,\n",
        "                do_sample=False,\n",
        "                attention_mask=torch.ones_like(ids),\n",
        "                pad_token_id=tok_base.eos_token_id\n",
        "            )\n",
        "    text = tok_base.decode(gen[0])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGFpk_z0_OVK"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SP0Fumk4g2OP",
        "outputId": "228e30b5-9116-4654-f7e5-963572fa7fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running full evaluation on 500 questions (Phase 1: Raw outputs only)...\n",
            "\n",
            "Processing question 0/500...\n",
            "\n",
            "Phase 1 evaluation complete! Raw outputs saved.\n",
            "Next: Switch to CPU runtime and run Phase 2 for DeepSeek adjudication.\n"
          ]
        }
      ],
      "source": [
        "# Full evaluation on 500 questions - Phase 1: Generate raw outputs only\n",
        "print(\"Running full evaluation on 500 questions (Phase 1: Raw outputs only)...\\n\")\n",
        "\n",
        "rows = []\n",
        "for i, ex in enumerate(gsm_test):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Processing question {i}/500...\")\n",
        "\n",
        "    q_raw, gold_raw = ex[\"question\"], ex[\"answer\"]\n",
        "    gold_num = gold_int(gold_raw)\n",
        "\n",
        "    # Get baseline answer (raw text only)\n",
        "    base_text = baseline_answer(q_raw)\n",
        "\n",
        "    # Get thinking model answer (raw text only)\n",
        "    think_text, steps, ent, stop_reason = think_gen(build_prompt(q_raw))\n",
        "\n",
        "    rows.append({\n",
        "        \"id\": i,\n",
        "        \"question\": q_raw,\n",
        "        \"gold\": gold_num,\n",
        "        \"steps\": steps,\n",
        "        \"entropy_avg\": sum(ent)/len(ent) if ent else 0,\n",
        "        \"stopping_reason\": stop_reason,\n",
        "        \"baseline_raw\": base_text.split(\"Test Question:\", 1)[-1].replace(\"\\n\", \" \\\\n \"),\n",
        "        \"think_raw\": think_text.split(\"Test Question:\", 1)[-1].replace(\"\\n\", \" \\\\n \")\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"/content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\", index=False)\n",
        "print(\"\\nPhase 1 evaluation complete! Raw outputs saved.\")\n",
        "print(\"Next: Switch to CPU runtime and run Phase 2 for DeepSeek adjudication.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OCMFK4Zpdiy2",
        "outputId": "c8ba221b-b702-4a55-8565-925dc9456b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Phase 1 Complete: Generated raw outputs for 500 GSM-8K questions\n",
            "Raw outputs saved to: /content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Next step: Switch runtime to CPU and run Phase 2 for DeepSeek adjudication.\n"
          ]
        }
      ],
      "source": [
        "# Basic Phase 1 Statistics (no accuracy analysis yet)\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(f\"Phase 1 Complete: Generated raw outputs for 500 GSM-8K questions\")\n",
        "print(f\"Raw outputs saved to: /content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Thinking steps distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df[\"steps\"], bins=range(1, MAX_THINK_STEPS+2), alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Distribution of Thinking Steps\", fontsize=14)\n",
        "plt.xlabel(\"Number of Thinking Steps\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.axvline(df[\"steps\"].mean(), color='red', linestyle='dashed', linewidth=2,\n",
        "            label=f'Mean: {df[\"steps\"].mean():.1f}')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Stopping reasons distribution\n",
        "stop_counts = df[\"stopping_reason\"].value_counts()\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(stop_counts.index, stop_counts.values,\n",
        "               color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "plt.title(\"Distribution of Stopping Reasons\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.xlabel(\"Stopping Reason\", fontsize=12)\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNext step: Switch runtime to CPU and run Phase 2 for DeepSeek adjudication.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_UvwK9ndl7m",
        "outputId": "b9ac1de3-2f28-4c6c-f0e2-204edf52b9b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1 data contains 75 rows with columns: ['id', 'question', 'gold', 'steps', 'entropy_avg', 'stopping_reason', 'baseline_raw', 'think_raw']\n",
            "File saved to: /content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\n"
          ]
        }
      ],
      "source": [
        "# Phase 1 data already saved above - this cell can be deleted or used for verification\n",
        "print(f\"Phase 1 data contains {len(df)} rows with columns: {list(df.columns)}\")\n",
        "print(f\"File saved to: /content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBxzdWhUBWRB"
      },
      "source": [
        "# Phase 2: DeepSeek Adjudication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N7bBd8a2K9I"
      },
      "outputs": [],
      "source": [
        "#**Instructions:**\n",
        "#1. Switch runtime to CPU\n",
        "#2. Run the cells below to send raw outputs to DeepSeek-Reasoner for answer extraction\n",
        "#3. This will take approximately 35 minutes (1000 API calls at 30 req/min)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrcmkQz72K9n",
        "outputId": "21095027-034c-4453-ce6f-a48b48f8210c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì DeepSeek API key found\n"
          ]
        }
      ],
      "source": [
        "# Install required packages and check environment\n",
        "!pip -q install --upgrade openai backoff\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI\n",
        "import backoff\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Verify API key is set\n",
        "api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = api_key\n",
        "assert \"DEEPSEEK_API_KEY\" in os.environ, \"Please set DEEPSEEK_API_KEY environment variable\"\n",
        "print(\"‚úì DeepSeek API key found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DNW-QrmAdLo",
        "outputId": "5370e218-bce9-4eb8-e7bd-423719153a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # connecting google drive to this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4-5gR8T2K9n",
        "outputId": "40aa5a60-3f40-49af-d21e-e1ef52681f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì DeepSeek helper functions defined\n"
          ]
        }
      ],
      "source": [
        "# DeepSeek configuration and helper functions\n",
        "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
        "DEEPSEEK_MODEL = \"deepseek-reasoner\"\n",
        "DEEPSEEK_SYSTEM_PROMPT = \"\"\"\n",
        "You are DeepSeek-Reasoner and you're helping me check answers from a different AI model. The other model was given a math word-problem QUESTION and\n",
        "it generate it's answer as MODEL_OUTPUT. Read the reasoning of the model and it's entire output.\n",
        "Sometimes you may find that the model gives an answer and then makes up another question and it's reasoning and answer and so on.\n",
        "Sometimes the model's reasoning ends abruptly and then it outputs the answer.\n",
        "You must be smart and identify the integer answer that the model asserted ONLY for the question we provide to you.\n",
        "Ignore all of the text the model may generate which is unrelated to the question.\n",
        "\n",
        "Respond STRICTLY in valid JSON:\n",
        "{ \"answer\": <integer> }\n",
        "\n",
        "Do not wrap the JSON in markdown, do not add keys, and do not explain.\n",
        "\"\"\"\n",
        "RESPONSE_FORMAT = {\"type\": \"json_object\"}\n",
        "REQUEST_INTERVAL_SEC = 2.1  # ~30 requests per minute\n",
        "MAX_RETRY_DELAY_SEC = 60\n",
        "\n",
        "# Initialize OpenAI client for DeepSeek\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
        "    base_url=DEEPSEEK_BASE_URL\n",
        ")\n",
        "\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (Exception,),  # Catch all exceptions for robustness\n",
        "    max_time=None,  # keep trying indefinitely\n",
        "    factor=2,\n",
        "    max_value=MAX_RETRY_DELAY_SEC\n",
        ")\n",
        "def deepseek_extract_answer(question: str, model_output: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extract integer answer from model output using DeepSeek-Reasoner.\n",
        "    Returns: (answer_integer, full_deepseek_response)\n",
        "    \"\"\"\n",
        "    user_msg = f\"QUESTION:\\n{question}\\n\\nMODEL_OUTPUT:\\n{model_output}\"\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=DEEPSEEK_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": DEEPSEEK_SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": user_msg}\n",
        "            ],\n",
        "            response_format=RESPONSE_FORMAT,\n",
        "            max_tokens=2000\n",
        "        )\n",
        "\n",
        "        full_text = resp.choices[0].message.content\n",
        "\n",
        "        # Best-effort JSON parse (in case CoT leaks); keep whole text\n",
        "        try:\n",
        "            # Find JSON in response\n",
        "            first_brace = full_text.find('{')\n",
        "            last_brace = full_text.rfind('}')\n",
        "            if first_brace != -1 and last_brace != -1:\n",
        "                json_str = full_text[first_brace:last_brace+1]\n",
        "                js = json.loads(json_str)\n",
        "                ans = str(js[\"answer\"])\n",
        "            else:\n",
        "                raise ValueError(\"No JSON found\")\n",
        "        except Exception as e:\n",
        "            print(f\"JSON parsing failed: {e}\")\n",
        "            # Fall back to last integer in text\n",
        "            ints = re.findall(r\"-?\\d+\", full_text)\n",
        "            ans = ints[-1] if ints else \"\"\n",
        "\n",
        "        return ans, full_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed: {e}\")\n",
        "        raise  # Let backoff handle retry\n",
        "\n",
        "print(\"‚úì DeepSeek helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhjjzBS12K9o",
        "outputId": "2a2ed3f4-7c95-4fdc-a0b2-13f098c79dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DeepSeek API with a sample question...\n",
            "Loaded 75 questions from Phase 1\n",
            "\n",
            "Test Question: A factory used to make tractors, but now makes silos. When they made tractors, they sold 10 tractors...\n",
            "Gold Answer: 10\n",
            "‚úì DeepSeek baseline extraction: 10\n",
            "  Full response: {\"answer\": 10}...\n",
            "\n",
            "DeepSeek API test successful! Ready for full processing.\n"
          ]
        }
      ],
      "source": [
        "# Test DeepSeek API with one sample\n",
        "print(\"Testing DeepSeek API with a sample question...\")\n",
        "\n",
        "# Load the Phase 1 data\n",
        "df_phase1 = pd.read_csv(\"/content/drive/MyDrive/gsm8k_think_metrics_phase1.csv\")\n",
        "print(f\"Loaded {len(df_phase1)} questions from Phase 1\")\n",
        "\n",
        "# Test with first question\n",
        "test_question = df_phase1.iloc[0][\"question\"]\n",
        "test_baseline_raw = df_phase1.iloc[0][\"baseline_raw\"].replace(\" \\\\n \", \"\\n\")\n",
        "test_gold = df_phase1.iloc[0][\"gold\"]\n",
        "\n",
        "print(f\"\\nTest Question: {test_question[:100]}...\")\n",
        "print(f\"Gold Answer: {test_gold}\")\n",
        "\n",
        "try:\n",
        "    # Test baseline\n",
        "    ans_baseline, raw_baseline = deepseek_extract_answer(test_question, test_baseline_raw)\n",
        "    print(f\"‚úì DeepSeek baseline extraction: {ans_baseline}\")\n",
        "    print(f\"  Full response: {raw_baseline[:200]}...\")\n",
        "\n",
        "    print(\"\\nDeepSeek API test successful! Ready for full processing.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå DeepSeek API test failed: {e}\")\n",
        "    print(\"Please check your API key and try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "WZUrjeOH2K9o",
        "outputId": "4416bb09-6252-4a92-dfb1-d4171f152e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Phase 2: DeepSeek adjudication for all 500 questions...\n",
            "This will take approximately 5.2 minutes\n",
            "Processing with 30 requests per minute to avoid rate limits.\n",
            "\n",
            "Processing question 0/500... (elapsed: 0.0min, remaining: 5.2min)\n",
            "JSON parsing failed: No JSON found\n",
            "JSON parsing failed: No JSON found\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-2885837728.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbaseline_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"baseline_raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \\\\n \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert back from CSV format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mans_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepseek_extract_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdf_phase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_int_ds\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdf_phase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_ds_raw\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backoff/_sync.py\u001b[0m in \u001b[0;36mretry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mmax_tries_exceeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtries\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_tries_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-1188432087.py\u001b[0m in \u001b[0;36mdeepseek_extract_answer\u001b[0;34m(question, model_output)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         resp = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEEPSEEK_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1086\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    973\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     def _send_handling_auth(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Phase 2: DeepSeek adjudication for all 500 questions\n",
        "print(\"Starting Phase 2: DeepSeek adjudication for all 500 questions...\")\n",
        "print(f\"This will take approximately {(len(df_phase1) * 2 * REQUEST_INTERVAL_SEC) / 60:.1f} minutes\")\n",
        "print(\"Processing with 30 requests per minute to avoid rate limits.\\n\")\n",
        "\n",
        "# Initialize new columns in the dataframe\n",
        "df_phase1[\"baseline_int_ds\"] = \"\"\n",
        "df_phase1[\"baseline_ds_raw\"] = \"\"\n",
        "df_phase1[\"think_int_ds\"] = \"\"\n",
        "df_phase1[\"think_ds_raw\"] = \"\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for idx, row in df_phase1.iterrows():\n",
        "    if idx % 50 == 0:\n",
        "        elapsed = (time.time() - start_time) / 60\n",
        "        remaining = (len(df_phase1) - idx) * 2 * REQUEST_INTERVAL_SEC / 60\n",
        "        print(f\"Processing question {idx}/500... (elapsed: {elapsed:.1f}min, remaining: {remaining:.1f}min)\")\n",
        "\n",
        "    question = row[\"question\"]\n",
        "\n",
        "    # Process baseline output\n",
        "    baseline_raw = row[\"baseline_raw\"].replace(\" \\\\n \", \"\\n\")  # Convert back from CSV format\n",
        "    try:\n",
        "        ans_b, raw_b = deepseek_extract_answer(question, baseline_raw)\n",
        "        df_phase1.at[idx, \"baseline_int_ds\"] = ans_b\n",
        "        df_phase1.at[idx, \"baseline_ds_raw\"] = raw_b\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process baseline for question {idx}: {e}\")\n",
        "        df_phase1.at[idx, \"baseline_int_ds\"] = \"\"\n",
        "        df_phase1.at[idx, \"baseline_ds_raw\"] = f\"ERROR: {str(e)}\"\n",
        "\n",
        "    time.sleep(REQUEST_INTERVAL_SEC)\n",
        "\n",
        "    # Process thinking output\n",
        "    think_raw = row[\"think_raw\"].replace(\" \\\\n \", \"\\n\")  # Convert back from CSV format\n",
        "    try:\n",
        "        ans_t, raw_t = deepseek_extract_answer(question, think_raw)\n",
        "        df_phase1.at[idx, \"think_int_ds\"] = ans_t\n",
        "        df_phase1.at[idx, \"think_ds_raw\"] = raw_t\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process thinking for question {idx}: {e}\")\n",
        "        df_phase1.at[idx, \"think_int_ds\"] = \"\"\n",
        "        df_phase1.at[idx, \"think_ds_raw\"] = f\"ERROR: {str(e)}\"\n",
        "\n",
        "    time.sleep(REQUEST_INTERVAL_SEC)\n",
        "\n",
        "# Calculate correctness based on DeepSeek extractions\n",
        "df_phase1[\"correct_baseline_ds\"] = df_phase1[\"baseline_int_ds\"] == df_phase1[\"gold\"]\n",
        "df_phase1[\"correct_think_ds\"] = df_phase1[\"think_int_ds\"] == df_phase1[\"gold\"]\n",
        "\n",
        "# Save results\n",
        "output_path = \"/content/drive/MyDrive/gsm8k_think_metrics_deepseek.csv\"\n",
        "df_phase1.to_csv(output_path, index=False)\n",
        "\n",
        "total_time = (time.time() - start_time) / 60\n",
        "print(f\"\\n‚úì Phase 2 complete! Total time: {total_time:.1f} minutes\")\n",
        "print(f\"DeepSeek adjudication results saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0Fbf_ajq0ODp"
      },
      "outputs": [],
      "source": [
        "output_path = \"/content/drive/MyDrive/gsm8k_think_metrics_deepseek.csv\"\n",
        "df_phase1.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "RwzDcL1E2K9p",
        "outputId": "18f44488-4831-40d4-eabf-72169de51125"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'correct_baseline_ds'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'correct_baseline_ds'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-2584216213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate accuracies using DeepSeek-extracted answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbase_acc_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct_baseline_ds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mthink_acc_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct_think_ds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4106\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4107\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3817\u001b[0m             ):\n\u001b[1;32m   3818\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3820\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3821\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'correct_baseline_ds'"
          ]
        }
      ],
      "source": [
        "# Final Results Analysis with DeepSeek Adjudication\n",
        "df_final = df_phase1  # Use the dataframe with DeepSeek results\n",
        "\n",
        "# Calculate accuracies using DeepSeek-extracted answers\n",
        "base_acc_ds = df_final[\"correct_baseline_ds\"].mean()\n",
        "think_acc_ds = df_final[\"correct_think_ds\"].mean()\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"FINAL RESULTS (DeepSeek-Reasoner Adjudicated)\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"Baseline œÜ-3 accuracy on 500 GSM-8K questions: {base_acc_ds:.2%}\")\n",
        "print(f\"Think-advance model accuracy: {think_acc_ds:.2%}\")\n",
        "print(f\"Improvement: {(think_acc_ds - base_acc_ds):.2%} ({(think_acc_ds/base_acc_ds - 1)*100:.1f}% relative)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Accuracy comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar([\"Baseline œÜ-3\", \"Think-Advance\"], [base_acc_ds, think_acc_ds],\n",
        "                color=['#1f77b4', '#ff7f0e'])\n",
        "plt.title(\"GSM-8K Accuracy Comparison (500 questions, DeepSeek-Reasoner adjudicated)\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, max(base_acc_ds, think_acc_ds) * 1.2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{height:.1%}', ha='center', va='bottom', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Thinking steps distribution (unchanged from Phase 1)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_final[\"steps\"], bins=range(1, 201), alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Distribution of Thinking Steps\", fontsize=14)\n",
        "plt.xlabel(\"Number of Thinking Steps\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.axvline(df_final[\"steps\"].mean(), color='red', linestyle='dashed', linewidth=2,\n",
        "            label=f'Mean: {df_final[\"steps\"].mean():.1f}')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Show some examples where thinking helped\n",
        "think_better = df_final[(df_final[\"correct_think_ds\"] == True) & (df_final[\"correct_baseline_ds\"] == False)]\n",
        "baseline_better = df_final[(df_final[\"correct_baseline_ds\"] == True) & (df_final[\"correct_think_ds\"] == False)]\n",
        "\n",
        "print(f\"\\nDetailed Analysis:\")\n",
        "print(f\"Cases where thinking model got it right but baseline didn't: {len(think_better)}\")\n",
        "print(f\"Cases where baseline got it right but thinking didn't: {len(baseline_better)}\")\n",
        "print(f\"Cases where both got it right: {((df_final['correct_baseline_ds'] == True) & (df_final['correct_think_ds'] == True)).sum()}\")\n",
        "print(f\"Cases where both got it wrong: {((df_final['correct_baseline_ds'] == False) & (df_final['correct_think_ds'] == False)).sum()}\")\n",
        "\n",
        "if len(think_better) > 0:\n",
        "    print(f\"\\nExample where thinking helped:\")\n",
        "    ex = think_better.iloc[0]\n",
        "    print(f\"Question: {ex['question'][:100]}...\")\n",
        "    print(f\"Gold: {ex['gold']}\")\n",
        "    print(f\"Baseline answer (DeepSeek): {ex['baseline_int_ds']}\")\n",
        "    print(f\"Think answer (DeepSeek): {ex['think_int_ds']}\")\n",
        "    print(f\"Think steps: {ex['steps']}\")\n",
        "\n",
        "print(f\"\\nFinal results saved to: /content/drive/MyDrive/gsm8k_think_metrics_deepseek.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IgpJrpg-SVw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0281bcbd48db41389320ad61e3a35638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "065d9ab425b74f1f81172b04d9a00222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dfa9e9f3f3342a7a8483405191edb9c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4b20733318374082b4c2f719ab8887f5",
            "value": "‚Äá2/2‚Äá[00:06&lt;00:00,‚Äá‚Äá2.90s/it]"
          }
        },
        "177d2a74408b439e87189275be492b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f9bdcda46744624b9ee959622480bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3728fa2f53b54cefb89ec90cf17e9e42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b20733318374082b4c2f719ab8887f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "502cb2ebfa0e4346b9600b77c5ac15d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5257c3774ff74ef2b1cfe8b2b5ca7db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93a2f68635b94c30817b5952911c1d5a",
              "IPY_MODEL_85a07f5a623d4f778f70d55e13b1f169",
              "IPY_MODEL_065d9ab425b74f1f81172b04d9a00222"
            ],
            "layout": "IPY_MODEL_502cb2ebfa0e4346b9600b77c5ac15d3"
          }
        },
        "74249229106d4000b892248499778635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79618bcaf1e44155bafd7e1026a94ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8eef8ec479465991d23d52a8d8e096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74410ef8b5646f9a78d2fec5aebd67a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74249229106d4000b892248499778635",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "85a07f5a623d4f778f70d55e13b1f169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ac3badae8a4795a617f56d4b99ce58",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d695db113fc146b6b35ce99ccc05624a",
            "value": 2
          }
        },
        "8dfa9e9f3f3342a7a8483405191edb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a2f68635b94c30817b5952911c1d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79618bcaf1e44155bafd7e1026a94ad6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2f9bdcda46744624b9ee959622480bef",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "9e57e969811e4657a0345f9e88011d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6f559346704e81bacb163aedbae15e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_177d2a74408b439e87189275be492b89",
            "value": 2
          }
        },
        "a74410ef8b5646f9a78d2fec5aebd67a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c037d4869a2d4d61bfe10c1e1287290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3728fa2f53b54cefb89ec90cf17e9e42",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0281bcbd48db41389320ad61e3a35638",
            "value": "‚Äá2/2‚Äá[00:12&lt;00:00,‚Äá‚Äá5.62s/it]"
          }
        },
        "c6256089aaad471290c1822f963a1d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d695db113fc146b6b35ce99ccc05624a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef76fa45ffc14e4faa3b0f859c411c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e8eef8ec479465991d23d52a8d8e096",
              "IPY_MODEL_9e57e969811e4657a0345f9e88011d6b",
              "IPY_MODEL_c037d4869a2d4d61bfe10c1e1287290f"
            ],
            "layout": "IPY_MODEL_c6256089aaad471290c1822f963a1d19"
          }
        },
        "f8ac3badae8a4795a617f56d4b99ce58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6f559346704e81bacb163aedbae15e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}