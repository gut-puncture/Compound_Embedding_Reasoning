{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05fd0141bb4247faab5a32f0197cae3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93cc27036d0042dd8d98e775755cd5da",
              "IPY_MODEL_bfdec590fcf74a03bb79df8c6ff8f326",
              "IPY_MODEL_1ad110b1eed24cafbb0639a8444f4663"
            ],
            "layout": "IPY_MODEL_bbcdaec268924169ac131bd1a84bf5be"
          }
        },
        "93cc27036d0042dd8d98e775755cd5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766aae60a2bb491f94978587133ca4f9",
            "placeholder": "​",
            "style": "IPY_MODEL_e439ccd1b8e444c0972c1f9f726a2bbc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bfdec590fcf74a03bb79df8c6ff8f326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56cef2876d504cb69be31646be2a2bb9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afcf6153c0a14a4280c3c8db1a536c0d",
            "value": 2
          }
        },
        "1ad110b1eed24cafbb0639a8444f4663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e1cf6b850046eeb72a5e8e90dc6262",
            "placeholder": "​",
            "style": "IPY_MODEL_32d14cb2495749dbbf43cb424fed4af8",
            "value": " 2/2 [00:04&lt;00:00,  1.99s/it]"
          }
        },
        "bbcdaec268924169ac131bd1a84bf5be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766aae60a2bb491f94978587133ca4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e439ccd1b8e444c0972c1f9f726a2bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56cef2876d504cb69be31646be2a2bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcf6153c0a14a4280c3c8db1a536c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63e1cf6b850046eeb72a5e8e90dc6262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d14cb2495749dbbf43cb424fed4af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2adac794aa2a435d96dd5492af371ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_009da125130a4bbfbd9ceb490bb9b61e",
              "IPY_MODEL_73636ea94c3c4a8c9cf6dd83c5d5fd15",
              "IPY_MODEL_57f507741e7548c2b7ff2892ffe3081a"
            ],
            "layout": "IPY_MODEL_3885e983291747e7971d1011405d4ed4"
          }
        },
        "009da125130a4bbfbd9ceb490bb9b61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4065f0bce5684c5d9b6b44072c37f7d0",
            "placeholder": "​",
            "style": "IPY_MODEL_fa648300ddc84f38b3449c48b45e727e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "73636ea94c3c4a8c9cf6dd83c5d5fd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7695df6dfe2423aab36aa755eb89dd1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24d76351ae214c718d05e6e52f155e32",
            "value": 2
          }
        },
        "57f507741e7548c2b7ff2892ffe3081a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7f966b6fb84642bb179bce69ec366b",
            "placeholder": "​",
            "style": "IPY_MODEL_afb03cab9a7c44259cc8a64a573718c0",
            "value": " 2/2 [00:06&lt;00:00,  3.02s/it]"
          }
        },
        "3885e983291747e7971d1011405d4ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4065f0bce5684c5d9b6b44072c37f7d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa648300ddc84f38b3449c48b45e727e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7695df6dfe2423aab36aa755eb89dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d76351ae214c718d05e6e52f155e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7f966b6fb84642bb179bce69ec366b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb03cab9a7c44259cc8a64a573718c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gut-puncture/Compound_Embedding_Reasoning/blob/main/Compound_Embedding_Reasoning_Fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyFA26h_0-ZN"
      },
      "source": [
        "# Compound Embedding Reasoning - Fixed Version\n",
        "\n",
        "This notebook implements the compound embedding reasoning experiment with all bugs fixed.\n",
        "\n",
        "Key fixes made:\n",
        "1. Fixed the answer extraction logic to handle multiple generated questions\n",
        "2. Fixed variable naming inconsistencies\n",
        "3. Added proper error handling\n",
        "4. Improved visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uczl8JUK0-ZR",
        "outputId": "7050cea0-c2c0-4f43-de57-ac614b130c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.1/512.1 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # connecting google drive to this notebook\n",
        "\n",
        "!pip -q install --upgrade \"transformers==4.41.2\" \"accelerate>=0.29.0\" \\\n",
        "                \"sentencepiece\" \"datasets\" \"pandas\" \"matplotlib\" \"huggingface_hub>=0.23.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RRELkG5b0-ZS"
      },
      "outputs": [],
      "source": [
        "import torch, re, math, pandas as pd, matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import random, textwrap\n",
        "\n",
        "# ---------- paths ---------------------------------------------------------\n",
        "MODEL_DIR           = \"/content/drive/MyDrive/phi3_3.8B\"   # your modified weights\n",
        "BASELINE_HF_MODEL   = \"microsoft/phi-3-mini-4k-instruct\"   # reference\n",
        "\n",
        "# ---------- thinking parameters ------------------------------------------\n",
        "ALPHA               = 0.20\n",
        "COMPOUND_P          = 0.85\n",
        "SAMPLE_P            = 0.80\n",
        "STOP_INV_PPL_AVG    = 1.00\n",
        "WINDOW              = 6\n",
        "MAX_THINK_STEPS     = 200\n",
        "\n",
        "# ---------- token markers -------------------------------------------------\n",
        "REASON_START = \"### Reasoning:\\n\"\n",
        "REASON_END   = \"###\"\n",
        "ANS_START    = \"### Answer:\\n\"\n",
        "\n",
        "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE   = torch.float16 if DEVICE == \"cuda\" else torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b0CJze0w0-ZS"
      },
      "outputs": [],
      "source": [
        "def create_compound_vector(model_outputs, embeddings, dtype, p=COMPOUND_P):\n",
        "    logits = model_outputs.logits[:, -1, :]\n",
        "    probs  = torch.softmax(logits, dim=-1)\n",
        "    sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
        "    cum    = torch.cumsum(sorted_probs, dim=-1)\n",
        "    mask   = cum <= p #all elements with cumulative prob less than p are True and all others False in mask\n",
        "    mask[..., 0] = True #first element is hard coded to True so we ALWAYS choose at least one element\n",
        "    sel_idx, sel_prob = sorted_idx[mask], sorted_probs[mask] #selecting all the token ids and their probs for which cumulative prob is less than p\n",
        "    vec = (embeddings(sel_idx) * (sel_prob).unsqueeze(-1)).sum(0, keepdim=True)\n",
        "    return vec.to(dtype).unsqueeze(0)\n",
        "\n",
        "def sample_token_normally(model_outputs, p=SAMPLE_P): #essentially the same function as above but gives just the sampled token id\n",
        "    logits = model_outputs.logits[:, -1, :]\n",
        "    probs  = torch.softmax(logits, dim=-1)\n",
        "    sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
        "    mask   = torch.cumsum(sorted_probs, dim=-1) <= p\n",
        "    mask[..., 0] = True\n",
        "    choice = torch.multinomial(sorted_probs[mask], 1)\n",
        "    return sorted_idx[mask][choice]\n",
        "\n",
        "def create_thinking_vector(comp_vec, samp_tok, embeddings, dtype, alpha=ALPHA):\n",
        "    samp_emb = embeddings(samp_tok).unsqueeze(0).to(dtype)\n",
        "    return (1-alpha)*samp_emb + alpha*comp_vec.to(dtype) #creating a weigthed sum of the sampled token vector and the compound vector\n",
        "\n",
        "class ThinkGenerator: #Completely AI written\n",
        "    \"\"\"\n",
        "    Callable: prompt -> (answer_text, steps, inv_ppl_list, entropy_list)\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "        self.model     = AutoModelForCausalLM.from_pretrained(\n",
        "                            model_path, torch_dtype=DTYPE, device_map=\"auto\")\n",
        "        self.embed     = self.model.model.embed_tokens\n",
        "        self.dtype     = next(self.model.parameters()).dtype\n",
        "        self.device    = next(self.model.parameters()).device\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def __call__(self, full_prompt:str):\n",
        "        ids   = self.tokenizer(full_prompt, return_tensors=\"pt\").input_ids.to(self.device) #converts string to tokens\n",
        "        embeds = self.embed(ids).to(self.dtype) #embeddings of the token ids\n",
        "        inv_hist, ent_hist = [], []\n",
        "\n",
        "        #Reasoning loop for model\n",
        "        for _ in range(MAX_THINK_STEPS):\n",
        "            outs   = self.model(inputs_embeds=embeds) #vector embeddings injected in model rather than token ids\n",
        "            logits = outs.logits[:, -1, :]\n",
        "            p      = torch.softmax(logits, dim=-1)\n",
        "            inv_hist.append(1 / p.max().item()) #history of inverse perplexity which is essentially reciprocal of top token prob\n",
        "            ent_hist.append(-(p * p.log()).sum().item())\n",
        "\n",
        "            #if average of last n elements is greater than the thrshold, we stop this loop\n",
        "            if len(inv_hist) >= WINDOW and sum(inv_hist[-WINDOW:])/WINDOW < STOP_INV_PPL_AVG:\n",
        "                break\n",
        "\n",
        "            comp = create_compound_vector(outs, self.embed, self.dtype)\n",
        "            tok  = sample_token_normally(outs)\n",
        "            vec  = create_thinking_vector(comp, tok, self.embed, self.dtype)\n",
        "            embeds = torch.cat([embeds, vec], 1) #adding the compound vector to the previous token vectors\n",
        "            ids    = torch.cat([ids, tok.unsqueeze(0)], 1)\n",
        "\n",
        "        # add delimiters + generate one integer answer\n",
        "        delim = self.tokenizer(f\"{REASON_END}\\n{ANS_START}\", add_special_tokens=False, #ended reasoning and added answer start token\n",
        "                               return_tensors=\"pt\").input_ids.to(self.device)\n",
        "        ids   = torch.cat([ids, delim], 1)\n",
        "        gen   = self.model.generate(ids, max_new_tokens=20, do_sample=False,\n",
        "                                    attention_mask=torch.ones_like(ids),\n",
        "                                    pad_token_id=self.tokenizer.eos_token_id)\n",
        "        text  = self.tokenizer.decode(gen[0])\n",
        "        return text, len(inv_hist), inv_hist, ent_hist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 8 few-shot examples so we can compare performace with 8 shot eval\n",
        "FEW_SHOT_BLOCK = \"\"\"\n",
        "Example Questions and Answers:\n",
        "Question: If you roll 2 standard six-sided dice, what is the probability that the sum is 5?\n",
        "### Reasoning:\n",
        "The pairs that sum to 5 are (1,4), (2,3), (3,2), (4,1).\\\n",
        " There are 4 favourable outcomes out of 36 total. Probability = 4/36 = 1/9.\n",
        "###\n",
        "### Answer:\n",
        "1/9\n",
        "\n",
        "Question: A rectangle has length 8 cm and width 5 cm. What is its area in square centimetres?\n",
        "### Reasoning:\n",
        "Area = length × width = 8 × 5 = 40 cm².\n",
        "###\n",
        "### Answer:\n",
        "40\n",
        "\n",
        "Question: Sarah has 3 red, 4 blue, and 5 green marbles. If she randomly chooses one, what is the probability it is blue?\n",
        "### Reasoning:\n",
        "Total marbles = 3+4+5 = 12. Blue count = 4. Probability = 4/12 = 1/3.\n",
        "###\n",
        "### Answer:\n",
        "1/3\n",
        "\n",
        "Question: What is 15 % of 80?\n",
        "### Reasoning:\n",
        "0.15 × 80 = 12.\n",
        "###\n",
        "### Answer:\n",
        "12\n",
        "\n",
        "Question: A train travels 180 km in 3 hours. What is its average speed in km per hour?\n",
        "### Reasoning:\n",
        "Speed = distance / time = 180 / 3 = 60 km/h.\n",
        "###\n",
        "### Answer:\n",
        "60\n",
        "\n",
        "Question: The number x satisfies 3x + 7 = 22. What is x?\n",
        "### Reasoning:\n",
        "3x = 22 − 7 = 15 ⇒ x = 15/3 = 5.\n",
        "###\n",
        "### Answer:\n",
        "5\n",
        "\n",
        "Question: A square has perimeter 24 cm. What is the length of one side in centimetres?\n",
        "### Reasoning:\n",
        "Perimeter = 4s ⇒ s = 24/4 = 6 cm.\n",
        "###\n",
        "### Answer:\n",
        "6\n",
        "\n",
        "Question: Mike scores 70, 80, 90 on three tests. What average must he score on a 4th test to have a mean of 85?\n",
        "### Reasoning:\n",
        "Desired total = 85×4 = 340. Current total = 70+80+90 = 240. Needed = 340−240 = 100.\n",
        "###\n",
        "### Answer:\n",
        "100\n",
        "\"\"\".strip()\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI model which is being evaluated to see how well you're able to solve few reasoning questions which all have integer answers.\n",
        "From the next line, I have given you a few examples of the kind of questions you can expect, how you must reason to solve them and how to answer.\n",
        "Then you will see the words \"Test Question\" which will be the question you need to answer in the test.\n",
        "Think between the reasoning tokens and then write the answer. You must always, always end the generation with the final integer answer.\n",
        "The final integer in your generation will be what I will take as your answer and if it doesn't match with the answer given, I will mark your answer wrong.\n",
        "This is the way I can automate your evaluation.\n",
        "Even more important is to simply answer just the test question and stop generating text after the integer answer. Do not generate any more tokens.\"\"\"\n"
      ],
      "metadata": {
        "id": "X7UkQIbQ6OxM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, textwrap\n",
        "\n",
        "gsm_test  = load_dataset(\"gsm8k\", \"main\", split=\"test\").shuffle(seed=42).select(range(500))\n",
        "\n",
        "tok_base  = AutoTokenizer.from_pretrained(BASELINE_HF_MODEL, trust_remote_code=True)\n",
        "mod_base  = AutoModelForCausalLM.from_pretrained(BASELINE_HF_MODEL,\n",
        "                                                 torch_dtype=DTYPE, device_map=\"auto\")\n",
        "\n",
        "think_gen = ThinkGenerator(MODEL_DIR)\n",
        "\n",
        "def build_prompt(question: str) -> str:\n",
        "    return f\"{SYSTEM_PROMPT}\\n{FEW_SHOT_BLOCK}\\n\\n Test Question: {question}\\n{REASON_START}\"\n",
        "\n",
        "def gold_int(ans: str) -> str:\n",
        "    ints = re.findall(r\"-?\\d+\", ans)\n",
        "    return ints[-1] if ints else \"\" #results in the final integer in the model's generation\n",
        "\n",
        "# Use the better answer extraction function\n",
        "def extract_first_answer_integer(text: str, question: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract the first integer that appears after the FIRST occurrence of '### Answer:'\n",
        "    that follows the given question. This prevents picking up integers from\n",
        "    subsequent generated questions.\n",
        "    \"\"\"\n",
        "    # First, find where the question appears\n",
        "    if question in text:\n",
        "        # Get text after the question\n",
        "        text_after_q = text.split(question, 1)[1]\n",
        "\n",
        "        # Find the first \"### Answer:\" after the question\n",
        "        if ANS_START in text_after_q:\n",
        "            answer_section = text_after_q.split(ANS_START, 1)[1]\n",
        "\n",
        "            # Extract the first integer from this answer section\n",
        "            # But stop at the next \"Question:\" if there is one.\n",
        "            #This is added because earlier the model would generate questions,reasoning and answers by itself in a single generation\n",
        "            next_q_pos = answer_section.find(\"Question:\")\n",
        "            if next_q_pos != -1: #means Question: wasn't found in the answer_section\n",
        "                answer_section = answer_section[:next_q_pos]\n",
        "\n",
        "            # Find the first integer\n",
        "            matches = re.findall(r\"-?\\d+\", answer_section)\n",
        "            if matches:\n",
        "                return matches[-1]\n",
        "\n",
        "    # Fallback: if we can't find the pattern, look for first answer section\n",
        "    if ANS_START in text:\n",
        "        parts = text.split(ANS_START)\n",
        "        if len(parts) > 1:\n",
        "            # Look at first answer section only\n",
        "            first_answer = parts[1]\n",
        "            next_q_pos = first_answer.find(\"Question:\")\n",
        "            if next_q_pos != -1:\n",
        "                first_answer = first_answer[:next_q_pos]\n",
        "            matches = re.findall(r\"-?\\d+\", first_answer)\n",
        "            if matches:\n",
        "                return matches[-1]\n",
        "\n",
        "    # Last resort: find any integer in the text\n",
        "    matches = re.findall(r\"-?\\d+\", text)\n",
        "    return matches[-1] if matches else \"\"\n",
        "\n",
        "@torch.inference_mode()\n",
        "def baseline_answer(question: str) -> (str, str):\n",
        "    prompt = build_prompt(question)\n",
        "    ids    = tok_base(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "    gen    = mod_base.generate( #answer generate by vanilla model for comparison. we defined the vanilla model's name and simply use that.\n",
        "                ids,\n",
        "                max_new_tokens=256,\n",
        "                do_sample=False,\n",
        "                attention_mask=torch.ones_like(ids),\n",
        "                pad_token_id=tok_base.eos_token_id\n",
        "            )\n",
        "    text = tok_base.decode(gen[0])\n",
        "    return text, extract_first_answer_integer(text, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "05fd0141bb4247faab5a32f0197cae3d",
            "93cc27036d0042dd8d98e775755cd5da",
            "bfdec590fcf74a03bb79df8c6ff8f326",
            "1ad110b1eed24cafbb0639a8444f4663",
            "bbcdaec268924169ac131bd1a84bf5be",
            "766aae60a2bb491f94978587133ca4f9",
            "e439ccd1b8e444c0972c1f9f726a2bbc",
            "56cef2876d504cb69be31646be2a2bb9",
            "afcf6153c0a14a4280c3c8db1a536c0d",
            "63e1cf6b850046eeb72a5e8e90dc6262",
            "32d14cb2495749dbbf43cb424fed4af8",
            "2adac794aa2a435d96dd5492af371ab0",
            "009da125130a4bbfbd9ceb490bb9b61e",
            "73636ea94c3c4a8c9cf6dd83c5d5fd15",
            "57f507741e7548c2b7ff2892ffe3081a",
            "3885e983291747e7971d1011405d4ed4",
            "4065f0bce5684c5d9b6b44072c37f7d0",
            "fa648300ddc84f38b3449c48b45e727e",
            "c7695df6dfe2423aab36aa755eb89dd1",
            "24d76351ae214c718d05e6e52f155e32",
            "2e7f966b6fb84642bb179bce69ec366b",
            "afb03cab9a7c44259cc8a64a573718c0"
          ]
        },
        "id": "NjJXcm_lC7LW",
        "outputId": "8f5eb99f-5155-4b3a-b1a4-c36a45fd79d8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05fd0141bb4247faab5a32f0197cae3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2adac794aa2a435d96dd5492af371ab0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "collapsed": true,
        "id": "pdxdKpbi0-ZT",
        "outputId": "d9c79dcc-baae-455e-941b-4c5413403782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================== \n",
            "SAMPLE 1\n",
            "Question:\n",
            "An ice cream truck is traveling through a neighborhood. Children\n",
            "from various homes have started chasing the truck and, by the time\n",
            "the truck has reached the end of the first street, there are 5\n",
            "children it. On the second street, each child is joined by another\n",
            "child and on the third street, each child in the existing group is\n",
            "joined by another 2 children. The original 5 children then give up\n",
            "and leave the group. How many children are now following the truck?\n",
            "Gold answer: 25 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cd2e78cd04a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mbase_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_raw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#vanilla model generates response with the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- BASELINE RAW (tail) ---\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#printing last 400 characters of the vanilla model's response to the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parsed integer  →\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_num\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#answer from vanilla model extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-cd2e78cd04a6>\u001b[0m in \u001b[0;36mbaseline_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mids\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtok_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     gen    = mod_base.generate( #answer generate by vanilla model for comparison. we defined the vanilla model's name and simply use that.\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1759\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_unfinished_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m             \u001b[0;31m# prepare model inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2394\u001b[0;31m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi3/modeling_phi3.py\u001b[0m in \u001b[0;36mprepare_inputs_for_generation\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, **kwargs)\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;31m# create position_ids on the fly for batch generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "##############################################################################\n",
        "### SANITY-CHECK CELL – run 5 questions first                             ###\n",
        "##############################################################################\n",
        "\n",
        "NUM_SANITY = 5\n",
        "sample_question_idxs = random.sample(range(len(gsm_test)), NUM_SANITY)\n",
        "\n",
        "\n",
        "for k, idx in enumerate(sample_question_idxs, 1):\n",
        "    q_raw  = gsm_test[idx][\"question\"]         #question string\n",
        "    gold   = gold_int(gsm_test[idx][\"answer\"]) #answer extracted from the question string. it's always the last integer.\n",
        "\n",
        "    print(\"=\"*70, f\"\\nSAMPLE {k}\\nQuestion:\\n{textwrap.fill(q_raw, 68)}\")\n",
        "    print(\"Gold answer:\", gold, \"\\n\")\n",
        "\n",
        "    # baseline\n",
        "    base_text, base_num = baseline_answer(q_raw) #vanilla model generates response with the question\n",
        "    print(\"--- BASELINE RAW (tail) ---\\n\", base_text[-400:], \"\\n\") #printing last 400 characters of the vanilla model's response to the question\n",
        "    print(\"Parsed integer  →\", base_num)  #answer from vanilla model extracted\n",
        "\n",
        "    # think-advance\n",
        "    think_text, steps, inv, ent = think_gen(build_prompt(q_raw))\n",
        "    think_num = extract_first_answer_integer(think_text, q_raw)\n",
        "    print(\"--- THINK RAW (tail) ---\\n\", think_text[:], \"\\n\") #CHANGED THIS TO PRINT ALL CHARACTERS TO SEE. CHANGE TO -400:0\n",
        "    print(\"Parsed integer  →\", think_num)\n",
        "    print(\"Thinking steps  →\", steps,\n",
        "          \"  inv-ppl avg →\", f\"{sum(inv)/len(inv):.3f}\")\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "Nof7eWG30-ZV",
        "outputId": "8f707e1a-1abe-4cb1-8aca-bef8ee9f2436",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full evaluation on 500 questions...\n",
            "\n",
            "Processing question 0/500...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-55d5335b57de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get baseline answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbase_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Get thinking model answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-d85df9551061>\u001b[0m in \u001b[0;36mbaseline_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mids\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtok_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     gen    = mod_base.generate( #answer generate by vanilla model for comparison. we defined the vanilla model's name and simply use that.\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1759\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2398\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi3/modeling_phi3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi3/modeling_phi3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 )\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1132\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi3/modeling_phi3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         attn_outputs, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    853\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi3/modeling_phi3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mquery_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mquery_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtied_pointers_to_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 set_module_tensor_to_device(\n\u001b[0m\u001b[1;32m    361\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Full evaluation on 500 questions\n",
        "print(\"Running full evaluation on 500 questions...\\n\")\n",
        "\n",
        "rows = []\n",
        "for i, ex in enumerate(gsm_test):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Processing question {i}/500...\")\n",
        "\n",
        "    q_raw, gold_raw = ex[\"question\"], ex[\"answer\"]\n",
        "    gold_num = gold_int(gold_raw)\n",
        "\n",
        "    # Get baseline answer\n",
        "    base_text, base_num = baseline_answer(q_raw)\n",
        "\n",
        "    # Get thinking model answer\n",
        "    think_text, steps, inv, ent = think_gen(build_prompt(q_raw))\n",
        "    think_num = extract_first_answer_integer(think_text, q_raw)  # Use better function\n",
        "\n",
        "    rows.append({\n",
        "        \"id\": i,\n",
        "        \"question\": q_raw,\n",
        "        \"gold\": gold_num,\n",
        "        \"baseline_int\": base_num,\n",
        "        \"think_int\": think_num,\n",
        "        \"correct_baseline\": base_num == gold_num,\n",
        "        \"correct_think\": think_num == gold_num,\n",
        "        \"steps\": steps,\n",
        "        \"inv_ppl_avg\": sum(inv)/len(inv) if inv else 0,\n",
        "        \"entropy_avg\": sum(ent)/len(ent) if ent else 0,\n",
        "        \"baseline_raw\": base_text.split(\"Test Question:\", 1)[-1].replace(\"\\n\", \" \\\\n \"),\n",
        "        \"think_raw\": think_text.split(\"Test Question:\", 1)[-1].replace(\"\\n\", \" \\\\n \")\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"/content/drive/MyDrive/gsm8k_think_metrics_fixed.csv\", index=False)\n",
        "print(\"\\nEvaluation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "6WGfhECglrtt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uMZGdTsX0-ZV",
        "outputId": "941b467d-25d3-4376-d656-b8640362cd69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Baseline φ-3 accuracy on 500 GSM-8K questions: 43.48%\n",
            "Think-advance model accuracy: 52.17%\n",
            "Improvement: 8.70% (20.0% relative)\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 5 cases where thinking model got it right but baseline didn't.\n",
            "Example:\n",
            "Question: Lorraine and Colleen are trading stickers for buttons. Each large sticker is worth a large button or...\n",
            "Gold: 89\n",
            "Baseline: 107\n",
            "Think: 89\n",
            "Think steps: 200\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/gsm8k_think_metrics_fixed.csv\n"
          ]
        }
      ],
      "source": [
        "# Results Analysis and Visualization\n",
        "base_acc = df[\"correct_baseline\"].mean()\n",
        "think_acc = df[\"correct_think\"].mean()\n",
        "\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(f\"Baseline φ-3 accuracy on 500 GSM-8K questions: {base_acc:.2%}\")\n",
        "print(f\"Think-advance model accuracy: {think_acc:.2%}\")\n",
        "print(f\"Improvement: {(think_acc - base_acc):.2%} ({(think_acc/base_acc - 1)*100:.1f}% relative)\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Accuracy comparison\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar([\"Baseline φ-3\", \"Think-Advance\"], [base_acc, think_acc],\n",
        "                color=['#1f77b4', '#ff7f0e'])\n",
        "plt.title(\"GSM-8K Accuracy Comparison (500 questions, 2-shot CoT)\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, max(base_acc, think_acc) * 1.2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{height:.1%}', ha='center', va='bottom', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Thinking steps distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df[\"steps\"], bins=range(1, MAX_THINK_STEPS+2), alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Distribution of Thinking Steps\", fontsize=14)\n",
        "plt.xlabel(\"Number of Thinking Steps\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.axvline(df[\"steps\"].mean(), color='red', linestyle='dashed', linewidth=2,\n",
        "            label=f'Mean: {df[\"steps\"].mean():.1f}')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Show some examples where thinking helped\n",
        "think_better = df[(df[\"correct_think\"] == True) & (df[\"correct_baseline\"] == False)]\n",
        "if len(think_better) > 0:\n",
        "    print(f\"\\nFound {len(think_better)} cases where thinking model got it right but baseline didn't.\")\n",
        "    print(\"Example:\")\n",
        "    ex = think_better.iloc[0]\n",
        "    print(f\"Question: {ex['question'][:100]}...\")\n",
        "    print(f\"Gold: {ex['gold']}\")\n",
        "    print(f\"Baseline: {ex['baseline_int']}\")\n",
        "    print(f\"Think: {ex['think_int']}\")\n",
        "    print(f\"Think steps: {ex['steps']}\")\n",
        "\n",
        "print(f\"\\nResults saved to: /content/drive/MyDrive/gsm8k_think_metrics_fixed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "iEDUgyPt1WMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7314b48-f567-4b99-8d0a-344d8cf9c7d5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/gsm8k_think_metrics_fixed.csv\", index=False)"
      ],
      "metadata": {
        "id": "gvz--208Mj15"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: bro just give comments and tell me the reason. I am using an A100 GPU and the fucking time taken to go through the GSM 8k dataset is really, really high. How can I improve the speed? Some algorithmic improvement? Parallelisation? Better hardware runtime?\n",
        "\n",
        "# You're right, processing the entire GSM8k test set (500 questions by default here) can be time-consuming\n",
        "# even with an A100, especially with complex generation logic involving \"thinking steps\".\n",
        "\n",
        "# Here's a breakdown of reasons for the slowness and potential improvements:\n",
        "\n",
        "# 1. Sequential Processing: The code iterates through the dataset questions one by one.\n",
        "#    Each question triggers potentially multiple forward passes through the large language model (LLM).\n",
        "#    This is the most significant bottleneck.\n",
        "\n",
        "# 2. Multiple Model Calls per Question:\n",
        "#    - `baseline_answer`: Calls `mod_base.generate` once.\n",
        "#    - `ThinkGenerator.__call__`: Calls `self.model` in a loop (`MAX_THINK_STEPS` times potentially) and then `self.model.generate` once.\n",
        "#    This 'thinking' process, while potentially improving accuracy, significantly increases computation per question.\n",
        "\n",
        "# 3. LLM Inference Cost: LLMs are computationally expensive. Each forward pass and token generation takes time,\n",
        "#    and the time scales with the model size and sequence length. Phi-3 3.8B is a substantial model.\n",
        "\n",
        "# 4. Data Loading/Processing: While less likely the primary bottleneck compared to inference, loading the dataset\n",
        "#    and processing the text (tokenization, extraction) adds overhead.\n",
        "\n",
        "# 5. Python Overhead: Standard Python loop and function calls add some overhead, though minor compared to GPU inference.\n",
        "\n",
        "# ### Algorithmic Improvement (in this specific CoT context):\n",
        "# - **Reduce `MAX_THINK_STEPS`**: If the 'thinking' process isn't providing proportional accuracy gains after a certain number of steps, reducing this limit will directly cut down on the number of forward passes per question in the `ThinkGenerator`. You could analyze the `steps` distribution from a smaller run to see if the model converges quickly.\n",
        "# - **Optimize the Thinking Process**: Can the `create_compound_vector` and `create_thinking_vector` logic be simplified or made more efficient? (Less likely to yield dramatic speedups compared to reducing model calls).\n",
        "# - **Early Stopping Criteria**: Refine the `STOP_INV_PPL_AVG` and `WINDOW` criteria to stop the thinking process earlier if the model seems confident or stuck. The current `sum(inv_hist[-WINDOW:])/WINDOW < STOP_INV_PPL_AVG` is one approach, but maybe a sharper condition is possible.\n",
        "\n",
        "# ### Parallelisation: This is the MOST promising area for significant speedup.\n",
        "# - **Batch Processing**: Instead of processing one question at a time, you can process multiple questions in batches.\n",
        "#    - Modify `baseline_answer` and `ThinkGenerator.__call__` to accept lists/batches of prompts.\n",
        "#    - Pad inputs to the same length within a batch.\n",
        "#    - Process the batch through the model simultaneously. PyTorch and Hugging Face Transformers support this naturally when you pass batched tensors.\n",
        "#    - You'll need to manage the 'thinking' loop for a batch, potentially needing different numbers of steps per item, which adds complexity (e.g., masking finished sequences).\n",
        "# - **Multi-GPU (if available/applicable)**: If you have multiple GPUs, you could distribute the model or batches across them. (Colab A100 instances are typically single-GPU).\n",
        "# - **Parallelizing across Questions**: Use Python's `multiprocessing` or `concurrent.futures` to run the `baseline_answer` and `think_gen` calls for different questions in separate processes. However, since the core bottleneck is GPU inference, this will likely only help if you can offload some CPU work or if there are stages that aren't fully saturating the GPU. For pure inference, batching is usually better.\n",
        "\n",
        "# ### Better Hardware/Runtime:\n",
        "# - **Larger Batch Size**: An A100 has significant VRAM (40GB or 80GB). You can likely increase the batch size considerably when implementing batch processing, which directly improves throughput. Experiment to find the largest batch size that fits in memory without crashing.\n",
        "# - **Faster Storage**: Ensure your Google Drive connection isn't a bottleneck for loading the model weights. Storing weights directly on the Colab instance storage might be slightly faster if you have enough space, but likely minimal impact compared to inference speed.\n",
        "# - **Quantization**: If accuracy allows, quantizing the model (e.g., to 8-bit or 4-bit) can dramatically reduce memory usage and potentially speed up inference, though it often requires specific hardware support or libraries (like `bitsandbytes`).\n",
        "\n",
        "# ### Implementation Strategy for Speedup:\n",
        "# 1. **Start with Batching `baseline_answer`**: This is simpler to implement as it's a single generation call. Modify `baseline_answer` to take a list of questions, build a batch of prompts, tokenize/pad, generate, and then process the results for the batch.\n",
        "# 2. **Implement Batching for `ThinkGenerator.__call__`**: This is more complex due to the iterative nature of the thinking loop and variable steps. You'll need to manage sequences within the batch independently until they meet the stopping criteria or hit `MAX_THINK_STEPS`. This involves tracking which sequences are 'finished' and masking them out of subsequent computations.\n",
        "# 3. **Experiment with Batch Size**: Once batching is working, find the optimal batch size that fits your A100 VRAM.\n",
        "# 4. **Analyze `MAX_THINK_STEPS`**: After implementing batching, evaluate performance and accuracy with different `MAX_THINK_STEPS` values.\n",
        "\n",
        "# **In summary, the primary way to speed this up dramatically on an A100 is to implement batch processing for both the baseline and the think-advance generation steps.** This will leverage the GPU's ability to process data in parallel.\n",
        "\n",
        "# The current code structure processes each question fully before starting the next, which is inefficient for GPU utilization.\n"
      ],
      "metadata": {
        "id": "NUr8RN4jMsRU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}